# MySvmBayes



概要：
    输入任意英文的电影评论(如good、bad、Tom Hanks)，会分析出是积极的还是消极的 (训练集是电影评论)
    支持向量机中迭代参数为20，正则化参数为 0.1
    用scala语言写了一个项目，可以去预测一些英文的情感分类，在对话框输入一个英文，经过这两个算法、也就是对应的两个模型预测出来这个英文的结果是什么。这里面第1个模型是线性分类支持向量机，第2个模型是朴素贝叶斯算法，然后你输入一段英文，它就会告诉你结果。因为我使用的训练集是自英文的电影评论网站爬虫得来，它都是真的电影评论，不是针对口头的日常用语，所以在预测日常用语上会由于语料库的不同、导致得到的结果的准确率不高。但是如果预测一些电影评论，是非常准确的。比如你输入一个Tom Hanks,因为汤姆汉克斯的电影的一般都还不错、所以答案是positive。
其中训练集有6万多条，用交叉验证的方法，把这6万多条分成了80%的20%。然后用得到的训练模型(80%是训练集)去训练那20%的测试集，得到的结果是线性分类支持向量机有82%的准确性，朴素贝叶斯有79%的准确性。


实现:
    整个项目分为两个模块，第一个模块是通过训练集训练出来两个模型；第二个模块就是把我们训练出来的模型加载、去计算输入的结果，然后把结果展示出来。
具体做法为：打开guithub。训练集neg.txt里面放了3万多条消极的训练集，positive.txt对应的都是积极的评论，然后我用分类训练器去做数据处理和模型训练。
首先做数据的过滤，把不影响结果的的一些字符删掉，比如文本里面的空格、冒号、逗号、句号都移除了(感叹号、问号，这些可能跟情绪有关系，所以我保留了)，然后把它归成一个DataFrame：一个是words(对应每个词)一个是手动标注value(negative是0、positive是1)，一个random用来做数据乱序。然后把数据整合(union)计算data得到64,780条数据。
    然后把刚才得到的这个词向量，用文本特征提取的工具，把词向量通过哈希运算，得到了一列TFIDF，相当于把计算机识别不了的字符串转成数字。接着会把这训练集一分为二，变成80%和20%。一个是训练集，一个是测试集，然后用线性可分的支持向量机，new一个算法，输入是TFIDF那一列，标签是我手动写的value(0和1)这一列，接着训练之后得到这个模型，把这个模型给存起来。
    以上是整个的训练过程，最后是对模型准确率进行评估，评估的结果是82%。
    NaiveBayes算法同上。
